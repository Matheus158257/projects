{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Pre-Processor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a component that process text for natural language processing using multiple packages.\n",
    "\n",
    "This notebook shows:\n",
    "    how to use the functionalities from the text processor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "import os\n",
    "import re\n",
    "import langdetect\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Master Class  Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLP():\n",
    "    \"\"\"\n",
    "    This class is the moder of all nlp classes.\n",
    "\n",
    "    \"\"\"\n",
    "    # Class Attribute\n",
    "\n",
    "    # Initializer / Instance Attributes\n",
    "    def __init__(self, texts_dir):\n",
    "        self.texts_dir = texts_dir\n",
    "        self.text_list = self.return_texts_dir()\n",
    "\n",
    "    def return_texts_dir(self):\n",
    "        \"\"\"\n",
    "        :return: Get a list of all the texts on the dir\n",
    "        \"\"\"\n",
    "        all_files = os.listdir(self.texts_dir)\n",
    "        text_list = []\n",
    "        for file in all_files:\n",
    "            text_list = text_list + [open(self.texts_dir + file, \"r\", encoding=\"utf-8\").read()]\n",
    "        return text_list\n",
    "\n",
    "    def get_unique_name_tokens(self):\n",
    "        \"\"\"\n",
    "        :return: All the tokens in the list of text without repetition\n",
    "        \"\"\"\n",
    "        vectorizer =  CountVectorizer()\n",
    "        vectorized_object = vectorizer.fit_transform(self.text_list)\n",
    "        return vectorizer.get_feature_names()\n",
    "\n",
    "    def get_main_language(self):\n",
    "        \"\"\"\n",
    "        :return: The main language of the text\n",
    "        \"\"\"\n",
    "        all_text = \" \".join(self.text_list)\n",
    "        return langdetect.detect(all_text)\n",
    "\n",
    "    def get_present_languages(self):\n",
    "        \"\"\"\n",
    "        :return: The languages detected on the text by probability score\n",
    "        \"\"\"\n",
    "        all_text = \" \".join(self.text_list)\n",
    "        return langdetect.detect_langs(all_text)\n",
    "\n",
    "    def get_all_words_with_end(self, word_end):\n",
    "        \"\"\"\n",
    "\n",
    "        :param word_end: the string of end to search on the text list\n",
    "        :return: the words in which the word end is present\n",
    "        \"\"\"\n",
    "        word_end_list = []\n",
    "        for word in self.get_unique_name_tokens():\n",
    "            if word.endswith(word_end):\n",
    "                word_end_list.append(word)\n",
    "        return word_end_list\n",
    "\n",
    "    def get_all_words_with_start(self, word_start):\n",
    "        \"\"\"\n",
    "        :param word_start: the string of start to search on the text list\n",
    "        :return: the words in which the word start is present\n",
    "        \"\"\"\n",
    "        word_start_list = []\n",
    "        for word in self.get_unique_name_tokens():\n",
    "            if word.startswith(word_start):\n",
    "                word_start_list.append(word)\n",
    "        # word_end_list = [word_end_list.append(word) for word in vocabulario if word.endswith(sufixo)]\n",
    "        return word_start_list\n",
    "\n",
    "    def organize_ngrams(self, ngrams=2):\n",
    "        \"\"\"\n",
    "\n",
    "        :param ngrams: number of words in the gram\n",
    "        :return: the text list organized in n-grams\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        vocab = defaultdict(int)\n",
    "        for sample in self.text_list:\n",
    "            tokens = re.findall(r'[\\w-]+', sample.lower())\n",
    "            for start in range(len(tokens) - ngrams):\n",
    "                end = start + ngrams\n",
    "                tok = ' '.join(tokens[start:end])\n",
    "                vocab[tok] += 1\n",
    "                # if tok not in ngrams_tokens_list:\n",
    "                #     ngrams_tokens_list.append(tok)\n",
    "        return list(vocab.keys())\n",
    "\n",
    "    def top_ngrams(self, ngrams=2, number_best_tokens=10):\n",
    "        \"\"\"\n",
    "        :param ngrams: number of words in the gram\n",
    "        :param number_best_tokens: The number of best tokens returned\n",
    "        :return: the top ngrams from your text list\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        vocab = defaultdict(int)\n",
    "        for sample in self.text_list:\n",
    "            tokens = re.findall(r'[\\w-]+', sample.lower())\n",
    "            for start in range(len(tokens) - ngrams):\n",
    "                end = start + ngrams\n",
    "                tok = ' '.join(tokens[start:end])\n",
    "                vocab[tok] += 1\n",
    "        all_tokens = sorted(vocab.items(), key=lambda i: i[1], reverse=True)\n",
    "        best_tokens = all_tokens[:number_best_tokens]\n",
    "        return best_tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Text Pre Processment Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class PreProcessament(NLP):\n",
    "    \"\"\"\n",
    "    This class is only for text pre-processment functionalities\n",
    "    \"\"\"\n",
    "    # Initializer / Instance Attributes\n",
    "    def __init__(self,dir_texts):\n",
    "        NLP.__init__(self, dir_texts)\n",
    "        self.main_language = self.get_main_language()\n",
    "        self.doc_list_spacy = self.set_doc_list_spacy()\n",
    "        self.token_names_matrix_spacy = self.get_token_names_matrix()\n",
    "\n",
    "    def get_token_numbers_matrix(self,TF_IDF = False):\n",
    "        \"\"\"\n",
    "\n",
    "        :param TF_IDF: If true matrix tf_idf se counting matrix\n",
    "        :return: Tokens matrix from sklearn\n",
    "        tf-idf: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "        counts:https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "\n",
    "        \"\"\"\n",
    "        if TF_IDF:\n",
    "            vectorizer = TfidfVectorizer()\n",
    "        else:\n",
    "            vectorizer = CountVectorizer()\n",
    "        vectorized_object = vectorizer.fit_transform(self.text_list)\n",
    "        return vectorized_object.toarray()\n",
    "\n",
    "    def set_doc_list_spacy(self):\n",
    "        \"\"\"\n",
    "        :return: list of docs format spacy\n",
    "\n",
    "        \"\"\"\n",
    "        language = 'pt_core_news_sm' if (self.main_language == 'pt') else 'en'\n",
    "        nlp = spacy.load(language)\n",
    "        docs_list = []\n",
    "        for text in self.text_list:\n",
    "            docs_list.append(nlp(text))\n",
    "\n",
    "        return docs_list\n",
    "\n",
    "\n",
    "    def get_token_names_matrix(self,punctuation=False,repeated_tokens=True,all_low_cap = True, token_spacy= True):\n",
    "        \n",
    "        \"\"\"\n",
    "        :param punctuation:If False punctuation (.,!? etc) removed else keeped\n",
    "        :param repeated_tokens:If True keep repeatables for text else remove\n",
    "        :param all_low_cap:If True return everything low cap\n",
    "        :param token_spacy:IF True return token_spacy else string\n",
    "        :return: Matrix of nominal tokens. If token_pacy = True is a type from Spacy else returns string\n",
    "        \"\"\"\n",
    "        language = 'pt_core_news_sm' if (self.main_language == 'pt') else 'en'\n",
    "        nlp = spacy.load(language)\n",
    "        name_tokens_list = []\n",
    "        for i, text in enumerate(self.text_list):\n",
    "            text = text if repeated_tokens else list(set(text))\n",
    "            text = text.lower() if all_low_cap else text\n",
    "            doc = nlp(text)\n",
    "            if token_spacy:\n",
    "                name_tokens_list.append([token for token in doc] if punctuation else [token for token in doc if not token.is_punct])\n",
    "            else:\n",
    "                name_tokens_list.append([token.orth_  for token in doc] if punctuation else [token.orth_  for token in doc if not token.is_punct])\n",
    "        return name_tokens_list\n",
    "\n",
    "    def split_text_into_sentences(self):\n",
    "        \"\"\"\n",
    "        :return: All the text joined\n",
    "        \"\"\"\n",
    "\n",
    "        all_text = \" \".join(self.text_list)\n",
    "        return nltk.tokenize.sent_tokenize(all_text)\n",
    "\n",
    "\n",
    "    def get_stop_words(self, language_stop_words):\n",
    "        \"\"\"\n",
    "        :param language_stop_words: language in string format\n",
    "        :return: Stop Words from  nltk package\n",
    "        \"\"\"\n",
    "\n",
    "        stopwords = nltk.corpus.stopwords.words(language_stop_words)\n",
    "        return stopwords\n",
    "\n",
    "    def remove_stop_words_vocab(self, stop_words, vocab):\n",
    "        \"\"\"\n",
    "\n",
    "        :param stop_words: words to remove\n",
    "        :param vocab: The words present in all sentences\n",
    "        :return: Vocab without stop words\n",
    "        \"\"\"\n",
    "\n",
    "        return list(set(vocab) - set(stop_words))\n",
    "\n",
    "    def tag_pos_list(self):\n",
    "        \"\"\"\n",
    "        :return: Part of speech(POS) with accuracy of 79.94%\n",
    "        \"\"\"\n",
    "\n",
    "        pos_list = []\n",
    "        for doc in self.token_names_matrix_spacy:\n",
    "            pos_list.append([(token.orth_, token.pos_) for token in doc])\n",
    "        return pos_list\n",
    "\n",
    "    def get_lemmatization(self,pos_list = ['NOUN','VERB','ADJ','NUM']):\n",
    "        \"\"\"\n",
    "        :param pos_list: List of part of speech as classified in spa\n",
    "        :return: List of lematized words according with the POS passed pos_list\n",
    "        \"\"\"\n",
    "\n",
    "        lemmas_list = []\n",
    "        for doc in self.token_names_matrix_spacy:\n",
    "            lemmas_list.append([token.lemma_ for token in doc  if token.pos_ in pos_list])\n",
    "        return lemmas_list\n",
    "\n",
    "    def recognize_entyties(self):\n",
    "        \"\"\"\n",
    "        :return: List of entities for each text\n",
    "        \"\"\"\n",
    "\n",
    "        entyties_list = []\n",
    "        for doc in self.doc_list_spacy:\n",
    "            entyties_list.append([(entity, entity.label_) for entity in doc.ents])\n",
    "        return entyties_list\n",
    "\n",
    "    def check_text_similarity(self,word1, word2):\n",
    "        \"\"\"\n",
    "\n",
    "        :param word1: first word\n",
    "        :param word2:  second word\n",
    "        :return: Similarity value from two words computed by spacy\n",
    "        \"\"\"\n",
    "\n",
    "        language = 'pt_core_news_sm' if (self.main_language == 'pt') else 'en'\n",
    "        nlp = spacy.load(language)\n",
    "        doc = nlp(word1 + ' ' + word2)\n",
    "        print(f'The similarity between {word1} and {word2} is: ', doc[0].similarity(doc[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Instantiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criação do objeto preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.PreProcessament at 0x230b992be80>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor = PreProcessament(\"textos_internet/noticias_agronegocio/\")\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Masterclass Funtionalities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Return texts on the directory\n",
    " Get a list of all the texts on the dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Confira a previsão do tempo para a primeira semana do outono\\nSomar Meteorologia indica que região do país terá chuva pesada nos próximos dias, com pancadas fortes e trovoadas; veja onde!\\nMarch 22, 2020 18:18  |  Redação - Canal Rural\\nChuva forte atinge propriedade rural\\n    \\nSegunda-feira, 21\\nSul\\nAinda há a ação de uma região de alta pressão atmosférica no oceano, que joga ventos úmidos do mar contra a costa. Assim, há condição para instabilidades na faixa leste, com eventual garoa e nevoeiros entre o leste do Paraná, Santa Catarina e litoral norte gaúcho. \\n \\nNo interior, o destaque passa a ser o sol. Com maior amplitude térmica, a manhã fica um pouco mais fria, mas a tarde segue quente especialmente nas áreas de fronteira com a Argentina.\\n \\nSudeste\\nÁreas de chuva mais pesada ficam concentradas no norte mineiro, com condição ainda para trovoadas e elevados volumes acumulados. Nos demais estados do Sudeste, a intensidade da chuva já diminui em relação aos dias anteriores e as chuvas ocorrem em forma de pancadas mais isoladas. \\n \\nO tempo segue fechado, nublado e com risco de chuva mais fraca entre o Vale do Paraíba, região metropolitana de São Paulo e Rio de Janeiro. \\n \\nCentro-Oeste\\nA previsão indica chuva generalizada e com declínio da temperatura entre Mato Grosso, Goiás e Distrito Federal. Isso acontece por causa da intensificação de uma área de baixa pressão atmosférica sobre o Mato Grosso. \\n \\n“Há potencial para transtornos localizados, inclusive no Distrito Federal, por conta da chuva forte e com trovoadas. Por outro lado, o tempo abre cada vez mais na metade sul do Mato Grosso do Sul”, diz a Somar.\\n \\nNordeste\\nA atenção fica para a chuva e rajadas de vento de até 70 km/h previstas para a Bahia, tanto na costa como no interior. Toda a faixa sul baiana tem muitas nuvens e chuva a qualquer hora, além de declínio da temperatura da tarde. \\n \\nPor outro lado, a chuva começa a diminuir na faixa norte do Nordeste, e se torna cada vez mais isolada e com baixo acumulado.\\n \\nNorte\\nO Norte ainda segue com condição para chuva generalizada entre sul do Pará e Tocantins. A combinação do calor e umidade da Amazônia com instabilidades tropicais forma chuvas com trovoadas entre Amazonas e Pará. Apenas o extremo norte da região é que fica com tempo mais firme.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.return_texts_dir()[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique names toquens\n",
    "All the tokens in the list of text without repetition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['08h25more_horiz',\n",
       " '10',\n",
       " '100',\n",
       " '10h21',\n",
       " '10h41more_horiz',\n",
       " '11',\n",
       " '11h23more_horiz',\n",
       " '12',\n",
       " '123',\n",
       " '12h29more_horiz']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.get_unique_name_tokens()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get main language on the text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pt'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.get_main_language()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remoção de Stop Words do vocabulário"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subtração da string dos stop words em relação ao vocabulário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[pt:0.9999955505359109]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.get_present_languages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The words in which the word start is present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in', 'inc', 'incentivando', 'incerteza', 'incertezas']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.get_all_words_with_start('in')[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The words in which the word end is present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['brunadinho', 'vizinho']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.get_all_words_with_end('inho')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The text list organized in n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['confira a previsão do',\n",
       " 'a previsão do tempo',\n",
       " 'previsão do tempo para',\n",
       " 'do tempo para a',\n",
       " 'tempo para a primeira']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.organize_ngrams(ngrams=4)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The top ngrams from your text list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('no momento do embarque', 3),\n",
       " ('prevê que a safra', 3),\n",
       " ('que a safra brasileira', 3),\n",
       " ('a maior da série', 3),\n",
       " ('maior da série histórica', 3),\n",
       " ('da série histórica do', 3),\n",
       " ('série histórica do instituto', 3),\n",
       " ('histórica do instituto iniciada', 3),\n",
       " ('do instituto iniciada em', 3),\n",
       " ('instituto iniciada em 1975', 3)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.top_ngrams(ngrams=4, number_best_tokens=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TextPre Processment Funtionalities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token Numbers Matrix with counting strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 1],\n",
       "       ...,\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.get_token_numbers_matrix(TF_IDF = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token Numbers Matrix with TF-IDF strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.04233072,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.02436815, 0.        ,\n",
       "        0.02866533],\n",
       "       ...,\n",
       "       [0.        , 0.04783516, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.get_token_numbers_matrix(TF_IDF = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Doc List to Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Confira a previsão do tempo para a primeira semana do outono\n",
       " Somar Meteorologia indica que região do país terá chuva pesada nos próximos dias, com pancadas fortes e trovoadas; veja onde!\n",
       " March 22, 2020 18:18  |  Redação - Canal Rural\n",
       " Chuva forte atinge propriedade rural\n",
       "     \n",
       " Segunda-feira, 21\n",
       " Sul\n",
       " Ainda há a ação de uma região de alta pressão atmosférica no oceano, que joga ventos úmidos do mar contra a costa. Assim, há condição para instabilidades na faixa leste, com eventual garoa e nevoeiros entre o leste do Paraná, Santa Catarina e litoral norte gaúcho. \n",
       "  \n",
       " No interior, o destaque passa a ser o sol. Com maior amplitude térmica, a manhã fica um pouco mais fria, mas a tarde segue quente especialmente nas áreas de fronteira com a Argentina.\n",
       "  \n",
       " Sudeste\n",
       " Áreas de chuva mais pesada ficam concentradas no norte mineiro, com condição ainda para trovoadas e elevados volumes acumulados. Nos demais estados do Sudeste, a intensidade da chuva já diminui em relação aos dias anteriores e as chuvas ocorrem em forma de pancadas mais isoladas. \n",
       "  \n",
       " O tempo segue fechado, nublado e com risco de chuva mais fraca entre o Vale do Paraíba, região metropolitana de São Paulo e Rio de Janeiro. \n",
       "  \n",
       " Centro-Oeste\n",
       " A previsão indica chuva generalizada e com declínio da temperatura entre Mato Grosso, Goiás e Distrito Federal. Isso acontece por causa da intensificação de uma área de baixa pressão atmosférica sobre o Mato Grosso. \n",
       "  \n",
       " “Há potencial para transtornos localizados, inclusive no Distrito Federal, por conta da chuva forte e com trovoadas. Por outro lado, o tempo abre cada vez mais na metade sul do Mato Grosso do Sul”, diz a Somar.\n",
       "  \n",
       " Nordeste\n",
       " A atenção fica para a chuva e rajadas de vento de até 70 km/h previstas para a Bahia, tanto na costa como no interior. Toda a faixa sul baiana tem muitas nuvens e chuva a qualquer hora, além de declínio da temperatura da tarde. \n",
       "  \n",
       " Por outro lado, a chuva começa a diminuir na faixa norte do Nordeste, e se torna cada vez mais isolada e com baixo acumulado.\n",
       "  \n",
       " Norte\n",
       " O Norte ainda segue com condição para chuva generalizada entre sul do Pará e Tocantins. A combinação do calor e umidade da Amazônia com instabilidades tropicais forma chuvas com trovoadas entre Amazonas e Pará. Apenas o extremo norte da região é que fica com tempo mais firme.]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.set_doc_list_spacy()[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix of nominal tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[confira,\n",
       "  a,\n",
       "  previsão,\n",
       "  do,\n",
       "  tempo,\n",
       "  para,\n",
       "  a,\n",
       "  primeira,\n",
       "  semana,\n",
       "  do,\n",
       "  outono,\n",
       "  ,\n",
       "  somar,\n",
       "  meteorologia,\n",
       "  indica,\n",
       "  que,\n",
       "  região,\n",
       "  do,\n",
       "  país,\n",
       "  terá,\n",
       "  chuva,\n",
       "  pesada,\n",
       "  nos,\n",
       "  próximos,\n",
       "  dias,\n",
       "  com,\n",
       "  pancadas,\n",
       "  fortes,\n",
       "  e,\n",
       "  trovoadas,\n",
       "  veja,\n",
       "  onde,\n",
       "  ,\n",
       "  march,\n",
       "  22,\n",
       "  2020,\n",
       "  18:18,\n",
       "   ,\n",
       "  |,\n",
       "   ,\n",
       "  redação,\n",
       "  canal,\n",
       "  rural,\n",
       "  ,\n",
       "  chuva,\n",
       "  forte,\n",
       "  atinge,\n",
       "  propriedade,\n",
       "  rural,\n",
       "  \n",
       "      ,\n",
       "  segunda-feira,\n",
       "  21,\n",
       "  ,\n",
       "  sul,\n",
       "  ,\n",
       "  ainda,\n",
       "  há,\n",
       "  a,\n",
       "  ação,\n",
       "  de,\n",
       "  uma,\n",
       "  região,\n",
       "  de,\n",
       "  alta,\n",
       "  pressão,\n",
       "  atmosférica,\n",
       "  no,\n",
       "  oceano,\n",
       "  que,\n",
       "  joga,\n",
       "  ventos,\n",
       "  úmidos,\n",
       "  do,\n",
       "  mar,\n",
       "  contra,\n",
       "  a,\n",
       "  costa,\n",
       "  assim,\n",
       "  há,\n",
       "  condição,\n",
       "  para,\n",
       "  instabilidades,\n",
       "  na,\n",
       "  faixa,\n",
       "  leste,\n",
       "  com,\n",
       "  eventual,\n",
       "  garoa,\n",
       "  e,\n",
       "  nevoeiros,\n",
       "  entre,\n",
       "  o,\n",
       "  leste,\n",
       "  do,\n",
       "  paraná,\n",
       "  santa,\n",
       "  catarina,\n",
       "  e,\n",
       "  litoral,\n",
       "  norte,\n",
       "  gaúcho,\n",
       "  \n",
       "   ,\n",
       "  no,\n",
       "  interior,\n",
       "  o,\n",
       "  destaque,\n",
       "  passa,\n",
       "  a,\n",
       "  ser,\n",
       "  o,\n",
       "  sol,\n",
       "  com,\n",
       "  maior,\n",
       "  amplitude,\n",
       "  térmica,\n",
       "  a,\n",
       "  manhã,\n",
       "  fica,\n",
       "  um,\n",
       "  pouco,\n",
       "  mais,\n",
       "  fria,\n",
       "  mas,\n",
       "  a,\n",
       "  tarde,\n",
       "  segue,\n",
       "  quente,\n",
       "  especialmente,\n",
       "  nas,\n",
       "  áreas,\n",
       "  de,\n",
       "  fronteira,\n",
       "  com,\n",
       "  a,\n",
       "  argentina,\n",
       "  \n",
       "   ,\n",
       "  sudeste,\n",
       "  ,\n",
       "  áreas,\n",
       "  de,\n",
       "  chuva,\n",
       "  mais,\n",
       "  pesada,\n",
       "  ficam,\n",
       "  concentradas,\n",
       "  no,\n",
       "  norte,\n",
       "  mineiro,\n",
       "  com,\n",
       "  condição,\n",
       "  ainda,\n",
       "  para,\n",
       "  trovoadas,\n",
       "  e,\n",
       "  elevados,\n",
       "  volumes,\n",
       "  acumulados,\n",
       "  nos,\n",
       "  demais,\n",
       "  estados,\n",
       "  do,\n",
       "  sudeste,\n",
       "  a,\n",
       "  intensidade,\n",
       "  da,\n",
       "  chuva,\n",
       "  já,\n",
       "  diminui,\n",
       "  em,\n",
       "  relação,\n",
       "  a,\n",
       "  os,\n",
       "  dias,\n",
       "  anteriores,\n",
       "  e,\n",
       "  as,\n",
       "  chuvas,\n",
       "  ocorrem,\n",
       "  em,\n",
       "  forma,\n",
       "  de,\n",
       "  pancadas,\n",
       "  mais,\n",
       "  isoladas,\n",
       "  \n",
       "   ,\n",
       "  o,\n",
       "  tempo,\n",
       "  segue,\n",
       "  fechado,\n",
       "  nublado,\n",
       "  e,\n",
       "  com,\n",
       "  risco,\n",
       "  de,\n",
       "  chuva,\n",
       "  mais,\n",
       "  fraca,\n",
       "  entre,\n",
       "  o,\n",
       "  vale,\n",
       "  do,\n",
       "  paraíba,\n",
       "  região,\n",
       "  metropolitana,\n",
       "  de,\n",
       "  são,\n",
       "  paulo,\n",
       "  e,\n",
       "  rio,\n",
       "  de,\n",
       "  janeiro,\n",
       "  \n",
       "   ,\n",
       "  centro-oeste,\n",
       "  ,\n",
       "  a,\n",
       "  previsão,\n",
       "  indica,\n",
       "  chuva,\n",
       "  generalizada,\n",
       "  e,\n",
       "  com,\n",
       "  declínio,\n",
       "  da,\n",
       "  temperatura,\n",
       "  entre,\n",
       "  mato,\n",
       "  grosso,\n",
       "  goiás,\n",
       "  e,\n",
       "  distrito,\n",
       "  federal,\n",
       "  isso,\n",
       "  acontece,\n",
       "  por,\n",
       "  causa,\n",
       "  da,\n",
       "  intensificação,\n",
       "  de,\n",
       "  uma,\n",
       "  área,\n",
       "  de,\n",
       "  baixa,\n",
       "  pressão,\n",
       "  atmosférica,\n",
       "  sobre,\n",
       "  o,\n",
       "  mato,\n",
       "  grosso,\n",
       "  \n",
       "   ,\n",
       "  há,\n",
       "  potencial,\n",
       "  para,\n",
       "  transtornos,\n",
       "  localizados,\n",
       "  inclusive,\n",
       "  no,\n",
       "  distrito,\n",
       "  federal,\n",
       "  por,\n",
       "  conta,\n",
       "  da,\n",
       "  chuva,\n",
       "  forte,\n",
       "  e,\n",
       "  com,\n",
       "  trovoadas,\n",
       "  por,\n",
       "  outro,\n",
       "  lado,\n",
       "  o,\n",
       "  tempo,\n",
       "  abre,\n",
       "  cada,\n",
       "  vez,\n",
       "  mais,\n",
       "  na,\n",
       "  metade,\n",
       "  sul,\n",
       "  do,\n",
       "  mato,\n",
       "  grosso,\n",
       "  do,\n",
       "  sul,\n",
       "  diz,\n",
       "  a,\n",
       "  somar,\n",
       "  \n",
       "   ,\n",
       "  nordeste,\n",
       "  ,\n",
       "  a,\n",
       "  atenção,\n",
       "  fica,\n",
       "  para,\n",
       "  a,\n",
       "  chuva,\n",
       "  e,\n",
       "  rajadas,\n",
       "  de,\n",
       "  vento,\n",
       "  de,\n",
       "  até,\n",
       "  70,\n",
       "  km,\n",
       "  h,\n",
       "  previstas,\n",
       "  para,\n",
       "  a,\n",
       "  bahia,\n",
       "  tanto,\n",
       "  na,\n",
       "  costa,\n",
       "  como,\n",
       "  no,\n",
       "  interior,\n",
       "  toda,\n",
       "  a,\n",
       "  faixa,\n",
       "  sul,\n",
       "  baiana,\n",
       "  tem,\n",
       "  muitas,\n",
       "  nuvens,\n",
       "  e,\n",
       "  chuva,\n",
       "  a,\n",
       "  qualquer,\n",
       "  hora,\n",
       "  além,\n",
       "  de,\n",
       "  declínio,\n",
       "  da,\n",
       "  temperatura,\n",
       "  da,\n",
       "  tarde,\n",
       "  \n",
       "   ,\n",
       "  por,\n",
       "  outro,\n",
       "  lado,\n",
       "  a,\n",
       "  chuva,\n",
       "  começa,\n",
       "  a,\n",
       "  diminuir,\n",
       "  na,\n",
       "  faixa,\n",
       "  norte,\n",
       "  do,\n",
       "  nordeste,\n",
       "  e,\n",
       "  se,\n",
       "  torna,\n",
       "  cada,\n",
       "  vez,\n",
       "  mais,\n",
       "  isolada,\n",
       "  e,\n",
       "  com,\n",
       "  baixo,\n",
       "  acumulado,\n",
       "  \n",
       "   ,\n",
       "  norte,\n",
       "  ,\n",
       "  o,\n",
       "  norte,\n",
       "  ainda,\n",
       "  segue,\n",
       "  com,\n",
       "  condição,\n",
       "  para,\n",
       "  chuva,\n",
       "  generalizada,\n",
       "  entre,\n",
       "  sul,\n",
       "  do,\n",
       "  pará,\n",
       "  e,\n",
       "  tocantins,\n",
       "  a,\n",
       "  combinação,\n",
       "  do,\n",
       "  calor,\n",
       "  e,\n",
       "  umidade,\n",
       "  da,\n",
       "  amazônia,\n",
       "  com,\n",
       "  instabilidades,\n",
       "  tropicais,\n",
       "  forma,\n",
       "  chuvas,\n",
       "  com,\n",
       "  trovoadas,\n",
       "  entre,\n",
       "  amazonas,\n",
       "  e,\n",
       "  pará,\n",
       "  apenas,\n",
       "  o,\n",
       "  extremo,\n",
       "  norte,\n",
       "  da,\n",
       "  região,\n",
       "  é,\n",
       "  que,\n",
       "  fica,\n",
       "  com,\n",
       "  tempo,\n",
       "  mais,\n",
       "  firme]]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.get_token_names_matrix(punctuation=False,repeated_tokens=True,all_low_cap = True, token_spacy= True)[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All the text joined in one string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Confira a previsão do tempo para a primeira semana do outono\\nSomar Meteorologia indica que região do país terá chuva pesada nos próximos dias, com pancadas fortes e trovoadas; veja onde!',\n",
       " 'March 22, 2020 18:18  |  Redação - Canal Rural\\nChuva forte atinge propriedade rural\\n    \\nSegunda-feira, 21\\nSul\\nAinda há a ação de uma região de alta pressão atmosférica no oceano, que joga ventos úmidos do mar contra a costa.']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.split_text_into_sentences()[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing stop words from vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['access_time11',\n",
       " 'aparente',\n",
       " 'mexer',\n",
       " 'ressaltou',\n",
       " 'produção',\n",
       " 'último',\n",
       " 'longa',\n",
       " '96',\n",
       " 'mudar',\n",
       " 'quedas',\n",
       " 'rapidamente',\n",
       " 'aumentam',\n",
       " 'incluem',\n",
       " 'sucessos',\n",
       " 'exemplo',\n",
       " 'confira',\n",
       " 'imune',\n",
       " 'causada',\n",
       " 'cadeia',\n",
       " 'segundo']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = preprocessor.get_stop_words('portuguese')\n",
    "vocab = preprocessor.get_unique_name_tokens()\n",
    "preprocessor.remove_stop_words_vocab(stop_words, vocab)[:20]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part of speech(POS) Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('confira', 'VERB'),\n",
       "  ('a', 'DET'),\n",
       "  ('previsão', 'NOUN'),\n",
       "  ('do', 'ADP'),\n",
       "  ('tempo', 'NOUN'),\n",
       "  ('para', 'ADP'),\n",
       "  ('a', 'DET'),\n",
       "  ('primeira', 'ADJ'),\n",
       "  ('semana', 'NOUN'),\n",
       "  ('do', 'PROPN'),\n",
       "  ('outono', 'PROPN'),\n",
       "  ('\\n', 'SPACE'),\n",
       "  ('somar', 'PROPN'),\n",
       "  ('meteorologia', 'NOUN'),\n",
       "  ('indica', 'VERB'),\n",
       "  ('que', 'SCONJ'),\n",
       "  ('região', 'PROPN'),\n",
       "  ('do', 'DET'),\n",
       "  ('país', 'NOUN'),\n",
       "  ('terá', 'VERB'),\n",
       "  ('chuva', 'NOUN'),\n",
       "  ('pesada', 'VERB'),\n",
       "  ('nos', 'PRON'),\n",
       "  ('próximos', 'ADJ'),\n",
       "  ('dias', 'NOUN'),\n",
       "  ('com', 'ADP'),\n",
       "  ('pancadas', 'NOUN'),\n",
       "  ('fortes', 'ADJ'),\n",
       "  ('e', 'CCONJ'),\n",
       "  ('trovoadas', 'ADJ'),\n",
       "  ('veja', 'VERB'),\n",
       "  ('onde', 'ADV'),\n",
       "  ('\\n', 'SPACE'),\n",
       "  ('march', 'PROPN'),\n",
       "  ('22', 'NUM'),\n",
       "  ('2020', 'NUM'),\n",
       "  ('18:18', 'NUM'),\n",
       "  (' ', 'SPACE'),\n",
       "  ('|', 'X'),\n",
       "  (' ', 'SPACE'),\n",
       "  ('redação', 'NOUN'),\n",
       "  ('canal', 'PROPN'),\n",
       "  ('rural', 'PROPN'),\n",
       "  ('\\n', 'SPACE'),\n",
       "  ('chuva', 'PROPN'),\n",
       "  ('forte', 'ADJ'),\n",
       "  ('atinge', 'VERB'),\n",
       "  ('propriedade', 'NOUN'),\n",
       "  ('rural', 'ADJ'),\n",
       "  ('\\n    \\n', 'SPACE'),\n",
       "  ('segunda-feira', 'PROPN'),\n",
       "  ('21', 'NUM'),\n",
       "  ('\\n', 'SPACE'),\n",
       "  ('sul', 'ADJ'),\n",
       "  ('\\n', 'SPACE'),\n",
       "  ('ainda', 'ADV'),\n",
       "  ('há', 'VERB'),\n",
       "  ('a', 'DET'),\n",
       "  ('ação', 'NOUN'),\n",
       "  ('de', 'ADP'),\n",
       "  ('uma', 'DET'),\n",
       "  ('região', 'NOUN'),\n",
       "  ('de', 'ADP'),\n",
       "  ('alta', 'ADJ'),\n",
       "  ('pressão', 'NOUN'),\n",
       "  ('atmosférica', 'ADJ'),\n",
       "  ('no', 'PROPN'),\n",
       "  ('oceano', 'PROPN'),\n",
       "  ('que', 'PRON'),\n",
       "  ('joga', 'VERB'),\n",
       "  ('ventos', 'NOUN'),\n",
       "  ('úmidos', 'ADJ'),\n",
       "  ('do', 'NUM'),\n",
       "  ('mar', 'NOUN'),\n",
       "  ('contra', 'ADP'),\n",
       "  ('a', 'DET'),\n",
       "  ('costa', 'NOUN'),\n",
       "  ('assim', 'ADV'),\n",
       "  ('há', 'VERB'),\n",
       "  ('condição', 'NOUN'),\n",
       "  ('para', 'ADP'),\n",
       "  ('instabilidades', 'NOUN'),\n",
       "  ('na', 'PROPN'),\n",
       "  ('faixa', 'PROPN'),\n",
       "  ('leste', 'ADJ'),\n",
       "  ('com', 'ADP'),\n",
       "  ('eventual', 'ADJ'),\n",
       "  ('garoa', 'NOUN'),\n",
       "  ('e', 'CCONJ'),\n",
       "  ('nevoeiros', 'NOUN'),\n",
       "  ('entre', 'ADP'),\n",
       "  ('o', 'DET'),\n",
       "  ('leste', 'NOUN'),\n",
       "  ('do', 'PROPN'),\n",
       "  ('paraná', 'PROPN'),\n",
       "  ('santa', 'PROPN'),\n",
       "  ('catarina', 'PROPN'),\n",
       "  ('e', 'CCONJ'),\n",
       "  ('litoral', 'PROPN'),\n",
       "  ('norte', 'PROPN'),\n",
       "  ('gaúcho', 'PROPN'),\n",
       "  ('\\n \\n', 'SPACE'),\n",
       "  ('no', 'ADP'),\n",
       "  ('interior', 'NOUN'),\n",
       "  ('o', 'DET'),\n",
       "  ('destaque', 'NOUN'),\n",
       "  ('passa', 'AUX'),\n",
       "  ('a', 'ADP'),\n",
       "  ('ser', 'VERB'),\n",
       "  ('o', 'DET'),\n",
       "  ('sol', 'NOUN'),\n",
       "  ('com', 'ADP'),\n",
       "  ('maior', 'ADJ'),\n",
       "  ('amplitude', 'NOUN'),\n",
       "  ('térmica', 'ADJ'),\n",
       "  ('a', 'DET'),\n",
       "  ('manhã', 'NOUN'),\n",
       "  ('fica', 'VERB'),\n",
       "  ('um', 'DET'),\n",
       "  ('pouco', 'DET'),\n",
       "  ('mais', 'ADV'),\n",
       "  ('fria', 'ADJ'),\n",
       "  ('mas', 'CCONJ'),\n",
       "  ('a', 'DET'),\n",
       "  ('tarde', 'NOUN'),\n",
       "  ('segue', 'VERB'),\n",
       "  ('quente', 'ADV'),\n",
       "  ('especialmente', 'ADV'),\n",
       "  ('nas', 'DET'),\n",
       "  ('áreas', 'NOUN'),\n",
       "  ('de', 'ADP'),\n",
       "  ('fronteira', 'NOUN'),\n",
       "  ('com', 'ADP'),\n",
       "  ('a', 'DET'),\n",
       "  ('argentina', 'PROPN'),\n",
       "  ('\\n \\n', 'SPACE'),\n",
       "  ('sudeste', 'VERB'),\n",
       "  ('\\n', 'SPACE'),\n",
       "  ('áreas', 'NOUN'),\n",
       "  ('de', 'ADP'),\n",
       "  ('chuva', 'NOUN'),\n",
       "  ('mais', 'ADV'),\n",
       "  ('pesada', 'VERB'),\n",
       "  ('ficam', 'VERB'),\n",
       "  ('concentradas', 'VERB'),\n",
       "  ('no', 'ADP'),\n",
       "  ('norte', 'NOUN'),\n",
       "  ('mineiro', 'ADJ'),\n",
       "  ('com', 'ADP'),\n",
       "  ('condição', 'NOUN'),\n",
       "  ('ainda', 'ADV'),\n",
       "  ('para', 'ADP'),\n",
       "  ('trovoadas', 'NOUN'),\n",
       "  ('e', 'CCONJ'),\n",
       "  ('elevados', 'VERB'),\n",
       "  ('volumes', 'NOUN'),\n",
       "  ('acumulados', 'VERB'),\n",
       "  ('nos', 'DET'),\n",
       "  ('demais', 'ADV'),\n",
       "  ('estados', 'NOUN'),\n",
       "  ('do', 'ADP'),\n",
       "  ('sudeste', 'NOUN'),\n",
       "  ('a', 'DET'),\n",
       "  ('intensidade', 'NOUN'),\n",
       "  ('da', 'ADP'),\n",
       "  ('chuva', 'NOUN'),\n",
       "  ('já', 'ADV'),\n",
       "  ('diminui', 'VERB'),\n",
       "  ('em', 'ADP'),\n",
       "  ('relação', 'NOUN'),\n",
       "  ('a', 'ADP'),\n",
       "  ('os', 'DET'),\n",
       "  ('dias', 'SYM'),\n",
       "  ('anteriores', 'ADJ'),\n",
       "  ('e', 'CCONJ'),\n",
       "  ('as', 'DET'),\n",
       "  ('chuvas', 'NOUN'),\n",
       "  ('ocorrem', 'VERB'),\n",
       "  ('em', 'ADP'),\n",
       "  ('forma', 'NOUN'),\n",
       "  ('de', 'ADP'),\n",
       "  ('pancadas', 'NOUN'),\n",
       "  ('mais', 'ADV'),\n",
       "  ('isoladas', 'VERB'),\n",
       "  ('\\n \\n', 'SPACE'),\n",
       "  ('o', 'DET'),\n",
       "  ('tempo', 'NOUN'),\n",
       "  ('segue', 'ADJ'),\n",
       "  ('fechado', 'VERB'),\n",
       "  ('nublado', 'VERB'),\n",
       "  ('e', 'CCONJ'),\n",
       "  ('com', 'ADP'),\n",
       "  ('risco', 'NOUN'),\n",
       "  ('de', 'ADP'),\n",
       "  ('chuva', 'NOUN'),\n",
       "  ('mais', 'ADV'),\n",
       "  ('fraca', 'ADJ'),\n",
       "  ('entre', 'ADP'),\n",
       "  ('o', 'DET'),\n",
       "  ('vale', 'NOUN'),\n",
       "  ('do', 'PROPN'),\n",
       "  ('paraíba', 'PROPN'),\n",
       "  ('região', 'NOUN'),\n",
       "  ('metropolitana', 'PROPN'),\n",
       "  ('de', 'ADP'),\n",
       "  ('são', 'PROPN'),\n",
       "  ('paulo', 'PROPN'),\n",
       "  ('e', 'CCONJ'),\n",
       "  ('rio', 'PROPN'),\n",
       "  ('de', 'ADP'),\n",
       "  ('janeiro', 'PROPN'),\n",
       "  ('\\n \\n', 'SPACE'),\n",
       "  ('centro-oeste', 'NOUN'),\n",
       "  ('\\n', 'SPACE'),\n",
       "  ('a', 'DET'),\n",
       "  ('previsão', 'NOUN'),\n",
       "  ('indica', 'ADJ'),\n",
       "  ('chuva', 'NOUN'),\n",
       "  ('generalizada', 'VERB'),\n",
       "  ('e', 'CCONJ'),\n",
       "  ('com', 'ADP'),\n",
       "  ('declínio', 'NOUN'),\n",
       "  ('da', 'ADP'),\n",
       "  ('temperatura', 'NOUN'),\n",
       "  ('entre', 'ADP'),\n",
       "  ('mato', 'PROPN'),\n",
       "  ('grosso', 'PROPN'),\n",
       "  ('goiás', 'PROPN'),\n",
       "  ('e', 'CCONJ'),\n",
       "  ('distrito', 'NOUN'),\n",
       "  ('federal', 'ADJ'),\n",
       "  ('isso', 'PRON'),\n",
       "  ('acontece', 'VERB'),\n",
       "  ('por', 'ADP'),\n",
       "  ('causa', 'NOUN'),\n",
       "  ('da', 'ADP'),\n",
       "  ('intensificação', 'NOUN'),\n",
       "  ('de', 'ADP'),\n",
       "  ('uma', 'DET'),\n",
       "  ('área', 'NOUN'),\n",
       "  ('de', 'ADP'),\n",
       "  ('baixa', 'ADJ'),\n",
       "  ('pressão', 'NOUN'),\n",
       "  ('atmosférica', 'ADJ'),\n",
       "  ('sobre', 'ADP'),\n",
       "  ('o', 'DET'),\n",
       "  ('mato', 'NOUN'),\n",
       "  ('grosso', 'PROPN'),\n",
       "  ('\\n \\n', 'SPACE'),\n",
       "  ('há', 'VERB'),\n",
       "  ('potencial', 'NOUN'),\n",
       "  ('para', 'ADP'),\n",
       "  ('transtornos', 'NOUN'),\n",
       "  ('localizados', 'VERB'),\n",
       "  ('inclusive', 'ADV'),\n",
       "  ('no', 'PROPN'),\n",
       "  ('distrito', 'NOUN'),\n",
       "  ('federal', 'ADJ'),\n",
       "  ('por', 'ADP'),\n",
       "  ('conta', 'NOUN'),\n",
       "  ('da', 'ADP'),\n",
       "  ('chuva', 'NOUN'),\n",
       "  ('forte', 'ADJ'),\n",
       "  ('e', 'CCONJ'),\n",
       "  ('com', 'ADP'),\n",
       "  ('trovoadas', 'NOUN'),\n",
       "  ('por', 'ADP'),\n",
       "  ('outro', 'DET'),\n",
       "  ('lado', 'NOUN'),\n",
       "  ('o', 'DET'),\n",
       "  ('tempo', 'NOUN'),\n",
       "  ('abre', 'VERB'),\n",
       "  ('cada', 'NOUN'),\n",
       "  ('vez', 'ADP'),\n",
       "  ('mais', 'NOUN'),\n",
       "  ('na', 'DET'),\n",
       "  ('metade', 'NOUN'),\n",
       "  ('sul', 'ADJ'),\n",
       "  ('do', 'ADP'),\n",
       "  ('mato', 'PROPN'),\n",
       "  ('grosso', 'PROPN'),\n",
       "  ('do', 'PROPN'),\n",
       "  ('sul', 'PROPN'),\n",
       "  ('diz', 'VERB'),\n",
       "  ('a', 'ADP'),\n",
       "  ('somar', 'VERB'),\n",
       "  ('\\n \\n', 'SPACE'),\n",
       "  ('nordeste', 'NOUN'),\n",
       "  ('\\n', 'SPACE'),\n",
       "  ('a', 'DET'),\n",
       "  ('atenção', 'NOUN'),\n",
       "  ('fica', 'VERB'),\n",
       "  ('para', 'ADP'),\n",
       "  ('a', 'DET'),\n",
       "  ('chuva', 'NOUN'),\n",
       "  ('e', 'CCONJ'),\n",
       "  ('rajadas', 'NOUN'),\n",
       "  ('de', 'ADP'),\n",
       "  ('vento', 'NOUN'),\n",
       "  ('de', 'ADP'),\n",
       "  ('até', 'ADP'),\n",
       "  ('70', 'NUM'),\n",
       "  ('km', 'SYM'),\n",
       "  ('h', 'ADP'),\n",
       "  ('previstas', 'NOUN'),\n",
       "  ('para', 'ADP'),\n",
       "  ('a', 'DET'),\n",
       "  ('bahia', 'PROPN'),\n",
       "  ('tanto', 'ADV'),\n",
       "  ('na', 'DET'),\n",
       "  ('costa', 'NOUN'),\n",
       "  ('como', 'ADV'),\n",
       "  ('no', 'DET'),\n",
       "  ('interior', 'NOUN'),\n",
       "  ('toda', 'DET'),\n",
       "  ('a', 'DET'),\n",
       "  ('faixa', 'NOUN'),\n",
       "  ('sul', 'ADJ'),\n",
       "  ('baiana', 'NOUN'),\n",
       "  ('tem', 'VERB'),\n",
       "  ('muitas', 'DET'),\n",
       "  ('nuvens', 'NOUN'),\n",
       "  ('e', 'CCONJ'),\n",
       "  ('chuva', 'NOUN'),\n",
       "  ('a', 'ADP'),\n",
       "  ('qualquer', 'DET'),\n",
       "  ('hora', 'NOUN'),\n",
       "  ('além', 'ADV'),\n",
       "  ('de', 'ADP'),\n",
       "  ('declínio', 'NOUN'),\n",
       "  ('da', 'ADP'),\n",
       "  ('temperatura', 'NOUN'),\n",
       "  ('da', 'ADP'),\n",
       "  ('tarde', 'ADV'),\n",
       "  ('\\n \\n', 'SPACE'),\n",
       "  ('por', 'ADP'),\n",
       "  ('outro', 'DET'),\n",
       "  ('lado', 'NOUN'),\n",
       "  ('a', 'DET'),\n",
       "  ('chuva', 'NOUN'),\n",
       "  ('começa', 'AUX'),\n",
       "  ('a', 'ADP'),\n",
       "  ('diminuir', 'VERB'),\n",
       "  ('na', 'DET'),\n",
       "  ('faixa', 'PROPN'),\n",
       "  ('norte', 'PROPN'),\n",
       "  ('do', 'ADP'),\n",
       "  ('nordeste', 'NOUN'),\n",
       "  ('e', 'CCONJ'),\n",
       "  ('se', 'PRON'),\n",
       "  ('torna', 'VERB'),\n",
       "  ('cada', 'NOUN'),\n",
       "  ('vez', 'ADP'),\n",
       "  ('mais', 'NOUN'),\n",
       "  ('isolada', 'VERB'),\n",
       "  ('e', 'CCONJ'),\n",
       "  ('com', 'ADP'),\n",
       "  ('baixo', 'ADJ'),\n",
       "  ('acumulado', 'VERB'),\n",
       "  ('\\n \\n', 'SPACE'),\n",
       "  ('norte', 'NOUN'),\n",
       "  ('\\n', 'SPACE'),\n",
       "  ('o', 'DET'),\n",
       "  ('norte', 'PROPN'),\n",
       "  ('ainda', 'ADV'),\n",
       "  ('segue', 'VERB'),\n",
       "  ('com', 'ADP'),\n",
       "  ('condição', 'NOUN'),\n",
       "  ('para', 'ADP'),\n",
       "  ('chuva', 'NOUN'),\n",
       "  ('generalizada', 'VERB'),\n",
       "  ('entre', 'ADP'),\n",
       "  ('sul', 'NOUN'),\n",
       "  ('do', 'PROPN'),\n",
       "  ('pará', 'VERB'),\n",
       "  ('e', 'CCONJ'),\n",
       "  ('tocantins', 'PROPN'),\n",
       "  ('a', 'DET'),\n",
       "  ('combinação', 'NOUN'),\n",
       "  ('do', 'ADP'),\n",
       "  ('calor', 'NOUN'),\n",
       "  ('e', 'CCONJ'),\n",
       "  ('umidade', 'NOUN'),\n",
       "  ('da', 'ADP'),\n",
       "  ('amazônia', 'NOUN'),\n",
       "  ('com', 'ADP'),\n",
       "  ('instabilidades', 'NOUN'),\n",
       "  ('tropicais', 'ADJ'),\n",
       "  ('forma', 'NOUN'),\n",
       "  ('chuvas', 'ADJ'),\n",
       "  ('com', 'ADP'),\n",
       "  ('trovoadas', 'NOUN'),\n",
       "  ('entre', 'ADP'),\n",
       "  ('amazonas', 'NOUN'),\n",
       "  ('e', 'CCONJ'),\n",
       "  ('pará', 'VERB'),\n",
       "  ('apenas', 'ADV'),\n",
       "  ('o', 'DET'),\n",
       "  ('extremo', 'ADJ'),\n",
       "  ('norte', 'NOUN'),\n",
       "  ('da', 'ADP'),\n",
       "  ('região', 'NOUN'),\n",
       "  ('é', 'ADP'),\n",
       "  ('que', 'SCONJ'),\n",
       "  ('fica', 'VERB'),\n",
       "  ('com', 'ADP'),\n",
       "  ('tempo', 'NOUN'),\n",
       "  ('mais', 'ADV'),\n",
       "  ('firme', 'ADJ')]]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.tag_pos_list()[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmas \n",
    "List of lematized words according with the POS passed pos_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['conferir',\n",
       "  'previsão',\n",
       "  'tempo',\n",
       "  'primeiro',\n",
       "  'semana',\n",
       "  'meteorologia',\n",
       "  'indicar',\n",
       "  'país',\n",
       "  'ter',\n",
       "  'chuva',\n",
       "  'pesar',\n",
       "  'próximo',\n",
       "  'dia',\n",
       "  'pancada',\n",
       "  'forte',\n",
       "  'trovoar',\n",
       "  'ver',\n",
       "  '22',\n",
       "  '2020',\n",
       "  '18:18',\n",
       "  'redação',\n",
       "  'forte',\n",
       "  'atingir',\n",
       "  'propriedade',\n",
       "  'rural',\n",
       "  '21',\n",
       "  'sul',\n",
       "  'haver',\n",
       "  'ação',\n",
       "  'região',\n",
       "  'alto',\n",
       "  'pressão',\n",
       "  'atmosférico',\n",
       "  'jogar',\n",
       "  'vento',\n",
       "  'úmidos',\n",
       "  'do',\n",
       "  'mar',\n",
       "  'costa',\n",
       "  'haver',\n",
       "  'condição',\n",
       "  'instabilidade',\n",
       "  'ler',\n",
       "  'eventual',\n",
       "  'garoa',\n",
       "  'nevoeiro',\n",
       "  'ler',\n",
       "  'interior',\n",
       "  'destacar',\n",
       "  'ser',\n",
       "  'sol',\n",
       "  'maior',\n",
       "  'amplitude',\n",
       "  'térmico',\n",
       "  'manhã',\n",
       "  'ficar',\n",
       "  'frio',\n",
       "  'tardar',\n",
       "  'seguir',\n",
       "  'área',\n",
       "  'fronteiro',\n",
       "  'sudeste',\n",
       "  'área',\n",
       "  'chuva',\n",
       "  'pesar',\n",
       "  'ficar',\n",
       "  'concentrar',\n",
       "  'norte',\n",
       "  'mineiro',\n",
       "  'condição',\n",
       "  'trovoar',\n",
       "  'elevar',\n",
       "  'volume',\n",
       "  'acumular',\n",
       "  'estar',\n",
       "  'sudeste',\n",
       "  'intensidade',\n",
       "  'chuva',\n",
       "  'diminuir',\n",
       "  'relação',\n",
       "  'anterior',\n",
       "  'chuva',\n",
       "  'ocorrer',\n",
       "  'formar',\n",
       "  'pancada',\n",
       "  'isolar',\n",
       "  'tempo',\n",
       "  'seguir',\n",
       "  'fechar',\n",
       "  'nublar',\n",
       "  'riscar',\n",
       "  'chuva',\n",
       "  'fraco',\n",
       "  'valer',\n",
       "  'região',\n",
       "  'centro-oeste',\n",
       "  'previsão',\n",
       "  'indicar',\n",
       "  'chuva',\n",
       "  'generalizar',\n",
       "  'declínio',\n",
       "  'temperatura',\n",
       "  'distrito',\n",
       "  'federal',\n",
       "  'acontecer',\n",
       "  'causar',\n",
       "  'intensificação',\n",
       "  'área',\n",
       "  'baixo',\n",
       "  'pressão',\n",
       "  'atmosférico',\n",
       "  'matar',\n",
       "  'haver',\n",
       "  'potencial',\n",
       "  'transtorno',\n",
       "  'localizar',\n",
       "  'distrito',\n",
       "  'federal',\n",
       "  'contar',\n",
       "  'chuva',\n",
       "  'forte',\n",
       "  'trovoar',\n",
       "  'lado',\n",
       "  'tempo',\n",
       "  'abrir',\n",
       "  'cada',\n",
       "  'mais',\n",
       "  'dois',\n",
       "  'sul',\n",
       "  'dizer',\n",
       "  'somar',\n",
       "  'nordeste',\n",
       "  'atenção',\n",
       "  'ficar',\n",
       "  'chuva',\n",
       "  'rajar',\n",
       "  'ventar',\n",
       "  '70',\n",
       "  'previsto',\n",
       "  'costa',\n",
       "  'interior',\n",
       "  'faixar',\n",
       "  'sul',\n",
       "  'baiano',\n",
       "  'ter',\n",
       "  'nuvem',\n",
       "  'chuva',\n",
       "  'horar',\n",
       "  'declínio',\n",
       "  'temperatura',\n",
       "  'lado',\n",
       "  'chuva',\n",
       "  'diminuir',\n",
       "  'nordeste',\n",
       "  'tornar',\n",
       "  'cada',\n",
       "  'mais',\n",
       "  'isolar',\n",
       "  'baixar',\n",
       "  'acumular',\n",
       "  'norte',\n",
       "  'seguir',\n",
       "  'condição',\n",
       "  'chuva',\n",
       "  'generalizar',\n",
       "  'sul',\n",
       "  'parar',\n",
       "  'combinação',\n",
       "  'calor',\n",
       "  'umidade',\n",
       "  'amazônia',\n",
       "  'instabilidade',\n",
       "  'tropicar',\n",
       "  'formar',\n",
       "  'chuva',\n",
       "  'trovoar',\n",
       "  'amazona',\n",
       "  'parar',\n",
       "  'extremar',\n",
       "  'norte',\n",
       "  'região',\n",
       "  'ficar',\n",
       "  'tempo',\n",
       "  'firmar']]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.get_lemmatization(pos_list = ['NOUN','VERB','ADJ','NUM'])[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entyties recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(Somar Meteorologia, 'PER'),\n",
       "  (March 22, 'MISC'),\n",
       "  (Redação - Canal Rural, 'MISC'),\n",
       "  (Chuva, 'PER'),\n",
       "  (Sul, 'LOC'),\n",
       "  (Paraná, 'LOC'),\n",
       "  (Santa Catarina, 'LOC'),\n",
       "  (Argentina, 'LOC'),\n",
       "  (Sudeste, 'LOC'),\n",
       "  (Áreas, 'LOC'),\n",
       "  (Sudeste, 'LOC'),\n",
       "  (Vale do Paraíba, 'LOC'),\n",
       "  (São Paulo, 'LOC'),\n",
       "  (Rio de Janeiro, 'LOC'),\n",
       "  (Centro-Oeste, 'LOC'),\n",
       "  (Mato Grosso, 'LOC'),\n",
       "  (Goiás, 'LOC'),\n",
       "  (Distrito Federal, 'LOC'),\n",
       "  (Mato Grosso, 'LOC'),\n",
       "  (“, 'LOC'),\n",
       "  (Distrito Federal, 'LOC'),\n",
       "  (Mato Grosso do Sul”, 'LOC'),\n",
       "  (Somar, 'LOC'),\n",
       "  (Nordeste, 'LOC'),\n",
       "  (Bahia, 'LOC'),\n",
       "  (Nordeste, 'LOC'),\n",
       "  (Norte, 'LOC'),\n",
       "  (Norte, 'LOC'),\n",
       "  (Pará, 'LOC'),\n",
       "  (Tocantins, 'LOC'),\n",
       "  (Amazônia, 'LOC'),\n",
       "  (Amazonas, 'LOC'),\n",
       "  (Pará, 'LOC')]]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.recognize_entyties()[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% mdgit \n"
    }
   },
   "outputs": [],
   "source": [
    "## Check if there is some similarity between two words\n",
    "Similarity goes from 0 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "preprocessor.check_text_similarity('falar','falar')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
